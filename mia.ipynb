{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert Bmp to png"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the directory containing the BMP images\n",
    "def convert_bmp_to_png(input_directory,output_directory):\n",
    "\n",
    "    for filename in os.listdir(input_directory):\n",
    "        if filename.lower().endswith('.bmp'):\n",
    "            # Construct full file path\n",
    "            bmp_path = os.path.join(input_directory, filename)\n",
    "            # Open the BMP image\n",
    "            with Image.open(bmp_path) as bmp_image:\n",
    "                # Convert the file extension to .png\n",
    "                png_filename = os.path.splitext(filename)[0] + '.png'\n",
    "                png_path = os.path.join(output_directory, png_filename)\n",
    "                # Save the image as PNG\n",
    "                bmp_image.save(png_path, 'PNG')\n",
    "                print(f\"Converted {filename} to {png_filename}\")\n",
    "\n",
    "print(\"Conversion completed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dir = r'C:\\Users\\user\\Desktop\\medical_image_analysis\\Covid\\images'\n",
    "output_dir = r'C:\\Users\\user\\Desktop\\medical_image_analysis\\Covid_png_format\\covid_images'\n",
    "\n",
    "convert_bmp_to_png(input_dir,output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dir_covid_masks = r'C:\\Users\\user\\Desktop\\medical_image_analysis\\Covid\\masks'\n",
    "output_dir_covid_masks = r'C:\\Users\\user\\Desktop\\medical_image_analysis\\Covid_png_format\\covid_masks'\n",
    "\n",
    "convert_bmp_to_png(input_dir_covid_masks, output_dir_covid_masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dir_non_covid = r'C:\\Users\\user\\Desktop\\medical_image_analysis\\Non_Covid\\images'\n",
    "output_dir_non_covid = r'C:\\Users\\user\\Desktop\\medical_image_analysis\\Non_covid_png_format\\non_covid_images'\n",
    "\n",
    "convert_bmp_to_png(input_dir_non_covid,output_dir_non_covid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dir_non_covid_masks = r'C:\\Users\\user\\Desktop\\medical_image_analysis\\Non_Covid\\masks'\n",
    "output_dir_non_covid_masks = r'C:\\Users\\user\\Desktop\\medical_image_analysis\\Non_covid_png_format\\non_covid_masks'\n",
    "\n",
    "convert_bmp_to_png(input_dir_non_covid_masks,output_dir_non_covid_masks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "importing necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "import torch\n",
    "# from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "import albumentations as A\n",
    "# from albumentations.pytorch import ToTensorV2\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from keras.utils import Sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "augmentation_pipeline = A.Compose([\n",
    "        A.HorizontalFlip(p=0.5),\n",
    "        A.VerticalFlip(p=0.5),\n",
    "        A.Rotate(limit=20, p=0.5),\n",
    "        A.RandomResizedCrop(height=128, width=128, scale=(0.8, 1.0), p=0.5),\n",
    "        A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225))\n",
    "        # ToTensorV2()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_transform_pipeline = A.Compose([\n",
    "        A.HorizontalFlip(p=0.5),\n",
    "        A.VerticalFlip(p=0.5),\n",
    "        A.Rotate(limit=20, p=0.5),\n",
    "        A.RandomResizedCrop(height=128, width=128, scale=(0.8, 1.0), p=0.5)\n",
    "        # ToTensorV2()\n",
    "        # A.Resize(height=256, width=256)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_image_augmentation_pipeline = A.Compose([\n",
    "    A.Resize(height=128, width=128), \n",
    "    A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225))\n",
    "    # ToTensorV2()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_mask_augmentation_pipeline = A.Compose([\n",
    "    A.Resize(height=128, width=128),\n",
    "    \n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Augmentation method "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AugmentedDataset(Sequence):\n",
    "    def __init__(self, image_paths, mask_paths, image_size=(128,128),augment=False):\n",
    "        self.image_paths = image_paths\n",
    "        self.mask_paths = mask_paths\n",
    "        self.image_size = image_size\n",
    "        self.augment = augment\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        img_path = self.image_paths[index]\n",
    "        mask_path = self.mask_paths[index]\n",
    "\n",
    "        # for img_path, mask_path in zip(batch_image_paths, batch_mask_paths):\n",
    "        image = cv2.imread(img_path)\n",
    "        image = cv2.resize(image, self.image_size)\n",
    "        image = np.array(image)\n",
    "        mask = cv2.imread(mask_path)\n",
    "        mask = cv2.cvtColor(mask,cv2.COLOR_BGR2GRAY)\n",
    "        # mask = mask.resize(self.image_size)\n",
    "        mask = cv2.resize(mask, self.image_size)\n",
    "        mask = np.reshape(mask,mask.shape+(1,))\n",
    "\n",
    "        mask = np.array(mask)\n",
    "        # image = np.array(cv2.imre(img_path).convert(\"RGB\").resize(self.image_size))\n",
    "        # mask = np.array(Image.open(mask_path).resize(self.image_size))\n",
    "\n",
    "        if self.augment and os.path.basename(img_path).startswith('Non'):\n",
    "            augmented = augmentation_pipeline(image=image)\n",
    "            image = augmented['image']\n",
    "            augmented = mask_transform_pipeline(image=mask)\n",
    "            mask = augmented['image']\n",
    "        else:\n",
    "            if self.augment and os.path.basename(img_path).startswith('Val'):\n",
    "            # Apply resizing and normalization to validation data\n",
    "                augmented = val_image_augmentation_pipeline(image=image)\n",
    "                image = augmented['image']\n",
    "                augmented = val_mask_augmentation_pipeline(image=mask)\n",
    "                mask = augmented['image']\n",
    "\n",
    "        # img_arr = np.array(image)\n",
    "        # mask_arr = np.array(mask)\n",
    "\n",
    "        # img_path.append(image)\n",
    "        # mask_path.append(mask)\n",
    "\n",
    "        # images = np.array(images)\n",
    "        # masks = np.array(masks)\n",
    "        # print(type(image))\n",
    "        # print(type(mask))\n",
    "        return image, mask\n",
    "            \n",
    "    \n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "image_folder = r'C:\\Users\\user\\Desktop\\medical_image_analysis\\dataset\\train\\images'\n",
    "image_paths = glob(os.path.join(image_folder, '*png'))\n",
    "# mask_paths = ['path/to/mask1.bmp', 'path/to/non_mask2.bmp', ...]\n",
    "mask_folder = r'C:\\Users\\user\\Desktop\\medical_image_analysis\\dataset\\train\\masks'\n",
    "mask_paths = glob(os.path.join(mask_folder, '*png'))\n",
    "\n",
    "# Separate minority (non) and majority class data\n",
    "minority_image_paths = [img for img in image_paths if os.path.basename(img).startswith('Non')]\n",
    "minority_mask_paths = [msk for msk in mask_paths if os.path.basename(msk).startswith('Non')]\n",
    "\n",
    "majority_image_paths = [img for img in image_paths if not os.path.basename(img).startswith('Non')]\n",
    "majority_mask_paths = [msk for msk in mask_paths if not os.path.basename(msk).startswith('Non')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_image_folder = r'C:\\Users\\user\\Desktop\\medical_image_analysis\\dataset\\val\\images'\n",
    "val_masks_folder = r'C:\\Users\\user\\Desktop\\medical_image_analysis\\dataset\\val\\masks'\n",
    "\n",
    "val_image_paths = glob(os.path.join(val_image_folder, '*png'))\n",
    "val_mask_paths = glob(os.path.join(val_masks_folder, '*png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_image_paths = majority_image_paths + minority_image_paths\n",
    "train_mask_paths = majority_mask_paths + minority_mask_paths\n",
    "\n",
    "combined = list(zip(train_image_paths, train_mask_paths))\n",
    "np.random.shuffle(combined)\n",
    "train_image_paths, train_mask_paths = zip(*combined)\n",
    "train_image_paths = list(train_image_paths)\n",
    "train_mask_paths = list(train_mask_paths)\n",
    "\n",
    "# Create final training dataset with augmentation for minority class\n",
    "train_dataset = AugmentedDataset(train_image_paths, train_mask_paths, augment=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Validation dataset without augmentation\n",
    "val_dataset = AugmentedDataset(val_image_paths, val_mask_paths, augment=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(128, 128, 3) (128, 128, 1)\n"
     ]
    }
   ],
   "source": [
    "image, mask = train_dataset.__getitem__(0)\n",
    "print(image.shape, mask.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.layers import Conv2D, Conv2DTranspose,MaxPooling2D,Dropout,Rescaling\n",
    "# from keras.callbacks import EarlyStop\n",
    "# from keras.models import Sequential\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\backend.py:1398: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "input_shape = (128,128,3)\n",
    "inputs = keras.layers.Input(input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "rescaling = Rescaling(1. / 255)(inputs) # rescale input images to [0, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\pooling\\max_pooling2d.py:161: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "c1 = keras.layers.Conv2D(16,(3,3), activation='relu', kernel_initializer='he_normal',padding='same')(rescaling)\n",
    "c1 = keras.layers.Dropout(0.1)(c1)\n",
    "c1 = keras.layers.Conv2D(16,(3,3), activation='relu', kernel_initializer='he_normal',padding='same')(c1)\n",
    "p1 = keras.layers.MaxPooling2D(2,2)(c1)\n",
    "\n",
    "c2 = keras.layers.Conv2D(32,(3,3), activation='relu', kernel_initializer='he_normal',padding='same')(p1)\n",
    "c2 = keras.layers.Dropout(0.1)(c2)\n",
    "c2 = keras.layers.Conv2D(32,(3,3), activation='relu', kernel_initializer='he_normal',padding='same')(c2)\n",
    "p2 = keras.layers.MaxPooling2D(2,2)(c2)\n",
    "\n",
    "c3 = keras.layers.Conv2D(64,(3,3), activation='relu', kernel_initializer='he_normal',padding='same')(p2)\n",
    "c3 = keras.layers.Dropout(0.1)(c3)\n",
    "c3 = keras.layers.Conv2D(64,(3,3), activation='relu', kernel_initializer='he_normal',padding='same')(c3)\n",
    "p3 = keras.layers.MaxPooling2D(2,2)(c3)\n",
    "\n",
    "c4 = keras.layers.Conv2D(128,(3,3), activation='relu', kernel_initializer='he_normal',padding='same')(p3)\n",
    "c4 = keras.layers.Dropout(0.2)(c4)\n",
    "c4 = keras.layers.Conv2D(128,(3,3), activation='relu', kernel_initializer='he_normal',padding='same')(c4)\n",
    "p4 = keras.layers.MaxPooling2D(2,2)(c4)\n",
    "\n",
    "c5 = keras.layers.Conv2D(256,(3,3), activation='relu', kernel_initializer='he_normal',padding='same')(p4)\n",
    "c5 = keras.layers.Dropout(0.3)(c5)\n",
    "c5 = keras.layers.Conv2D(256,(3,3), activation='relu', kernel_initializer='he_normal',padding='same')(c5)\n",
    "\n",
    "u6 = keras.layers.Conv2DTranspose(128, (2,2), strides=(2,2), padding='same')(c5)\n",
    "u6 = keras.layers.concatenate([u6,c4])\n",
    "c6 = keras.layers.Conv2D(128,(3,3), activation='relu', kernel_initializer='he_normal',padding='same')(u6)\n",
    "c6 = keras.layers.Dropout(0.2)(c6)\n",
    "c6 = keras.layers.Conv2D(128,(3,3), activation='relu', kernel_initializer='he_normal',padding='same')(c6)\n",
    "\n",
    "u7 = keras.layers.Conv2DTranspose(64, (2,2), strides=(2,2), padding='same')(c6)\n",
    "u7 = keras.layers.concatenate([u7,c3])\n",
    "c7 = keras.layers.Conv2D(64,(3,3), activation='relu', kernel_initializer='he_normal',padding='same')(u7)\n",
    "c7 = keras.layers.Dropout(0.2)(c7)\n",
    "c7 = keras.layers.Conv2D(64,(3,3), activation='relu', kernel_initializer='he_normal',padding='same')(c7)\n",
    "\n",
    "u8 = keras.layers.Conv2DTranspose(32, (2,2), strides=(2,2), padding='same')(c7)\n",
    "u8 = keras.layers.concatenate([u8,c2])\n",
    "c8 = keras.layers.Conv2D(32,(3,3), activation='relu', kernel_initializer='he_normal',padding='same')(u8)\n",
    "c8 = keras.layers.Dropout(0.1)(c8)\n",
    "c8 = keras.layers.Conv2D(32,(3,3), activation='relu', kernel_initializer='he_normal',padding='same')(c8)\n",
    "\n",
    "u9 = keras.layers.Conv2DTranspose(16, (2,2), strides=(2,2), padding='same')(c8)\n",
    "u9 = keras.layers.concatenate([u9,c1])\n",
    "c9 = keras.layers.Conv2D(16,(3,3), activation='relu', kernel_initializer='he_normal',padding='same')(u9)\n",
    "c9 = keras.layers.Dropout(0.1)(c9)\n",
    "c9 = keras.layers.Conv2D(16,(3,3), activation='relu', kernel_initializer='he_normal',padding='same')(c9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = keras.layers.Conv2D(1, (1,1), activation = 'sigmoid')(c9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)        [(None, 128, 128, 3)]        0         []                            \n",
      "                                                                                                  \n",
      " rescaling (Rescaling)       (None, 128, 128, 3)          0         ['input_1[0][0]']             \n",
      "                                                                                                  \n",
      " conv2d (Conv2D)             (None, 128, 128, 16)         448       ['rescaling[0][0]']           \n",
      "                                                                                                  \n",
      " dropout (Dropout)           (None, 128, 128, 16)         0         ['conv2d[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_1 (Conv2D)           (None, 128, 128, 16)         2320      ['dropout[0][0]']             \n",
      "                                                                                                  \n",
      " max_pooling2d (MaxPooling2  (None, 64, 64, 16)           0         ['conv2d_1[0][0]']            \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv2d_2 (Conv2D)           (None, 64, 64, 32)           4640      ['max_pooling2d[0][0]']       \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)         (None, 64, 64, 32)           0         ['conv2d_2[0][0]']            \n",
      "                                                                                                  \n",
      " conv2d_3 (Conv2D)           (None, 64, 64, 32)           9248      ['dropout_1[0][0]']           \n",
      "                                                                                                  \n",
      " max_pooling2d_1 (MaxPoolin  (None, 32, 32, 32)           0         ['conv2d_3[0][0]']            \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv2d_4 (Conv2D)           (None, 32, 32, 64)           18496     ['max_pooling2d_1[0][0]']     \n",
      "                                                                                                  \n",
      " dropout_2 (Dropout)         (None, 32, 32, 64)           0         ['conv2d_4[0][0]']            \n",
      "                                                                                                  \n",
      " conv2d_5 (Conv2D)           (None, 32, 32, 64)           36928     ['dropout_2[0][0]']           \n",
      "                                                                                                  \n",
      " max_pooling2d_2 (MaxPoolin  (None, 16, 16, 64)           0         ['conv2d_5[0][0]']            \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv2d_6 (Conv2D)           (None, 16, 16, 128)          73856     ['max_pooling2d_2[0][0]']     \n",
      "                                                                                                  \n",
      " dropout_3 (Dropout)         (None, 16, 16, 128)          0         ['conv2d_6[0][0]']            \n",
      "                                                                                                  \n",
      " conv2d_7 (Conv2D)           (None, 16, 16, 128)          147584    ['dropout_3[0][0]']           \n",
      "                                                                                                  \n",
      " max_pooling2d_3 (MaxPoolin  (None, 8, 8, 128)            0         ['conv2d_7[0][0]']            \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv2d_8 (Conv2D)           (None, 8, 8, 256)            295168    ['max_pooling2d_3[0][0]']     \n",
      "                                                                                                  \n",
      " dropout_4 (Dropout)         (None, 8, 8, 256)            0         ['conv2d_8[0][0]']            \n",
      "                                                                                                  \n",
      " conv2d_9 (Conv2D)           (None, 8, 8, 256)            590080    ['dropout_4[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_transpose (Conv2DTr  (None, 16, 16, 128)          131200    ['conv2d_9[0][0]']            \n",
      " anspose)                                                                                         \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)   (None, 16, 16, 256)          0         ['conv2d_transpose[0][0]',    \n",
      "                                                                     'conv2d_7[0][0]']            \n",
      "                                                                                                  \n",
      " conv2d_10 (Conv2D)          (None, 16, 16, 128)          295040    ['concatenate[0][0]']         \n",
      "                                                                                                  \n",
      " dropout_5 (Dropout)         (None, 16, 16, 128)          0         ['conv2d_10[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_11 (Conv2D)          (None, 16, 16, 128)          147584    ['dropout_5[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_transpose_1 (Conv2D  (None, 32, 32, 64)           32832     ['conv2d_11[0][0]']           \n",
      " Transpose)                                                                                       \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate  (None, 32, 32, 128)          0         ['conv2d_transpose_1[0][0]',  \n",
      " )                                                                   'conv2d_5[0][0]']            \n",
      "                                                                                                  \n",
      " conv2d_12 (Conv2D)          (None, 32, 32, 64)           73792     ['concatenate_1[0][0]']       \n",
      "                                                                                                  \n",
      " dropout_6 (Dropout)         (None, 32, 32, 64)           0         ['conv2d_12[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_13 (Conv2D)          (None, 32, 32, 64)           36928     ['dropout_6[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_transpose_2 (Conv2D  (None, 64, 64, 32)           8224      ['conv2d_13[0][0]']           \n",
      " Transpose)                                                                                       \n",
      "                                                                                                  \n",
      " concatenate_2 (Concatenate  (None, 64, 64, 64)           0         ['conv2d_transpose_2[0][0]',  \n",
      " )                                                                   'conv2d_3[0][0]']            \n",
      "                                                                                                  \n",
      " conv2d_14 (Conv2D)          (None, 64, 64, 32)           18464     ['concatenate_2[0][0]']       \n",
      "                                                                                                  \n",
      " dropout_7 (Dropout)         (None, 64, 64, 32)           0         ['conv2d_14[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_15 (Conv2D)          (None, 64, 64, 32)           9248      ['dropout_7[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_transpose_3 (Conv2D  (None, 128, 128, 16)         2064      ['conv2d_15[0][0]']           \n",
      " Transpose)                                                                                       \n",
      "                                                                                                  \n",
      " concatenate_3 (Concatenate  (None, 128, 128, 32)         0         ['conv2d_transpose_3[0][0]',  \n",
      " )                                                                   'conv2d_1[0][0]']            \n",
      "                                                                                                  \n",
      " conv2d_16 (Conv2D)          (None, 128, 128, 16)         4624      ['concatenate_3[0][0]']       \n",
      "                                                                                                  \n",
      " dropout_8 (Dropout)         (None, 128, 128, 16)         0         ['conv2d_16[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_17 (Conv2D)          (None, 128, 128, 16)         2320      ['dropout_8[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_18 (Conv2D)          (None, 128, 128, 1)          17        ['conv2d_17[0][0]']           \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1941105 (7.40 MB)\n",
      "Trainable params: 1941105 (7.40 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = keras.Model(inputs = [inputs], outputs = [outputs])\n",
    "model.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpointer = keras.callbacks.ModelCheckpoint(r'C:\\Users\\user\\Desktop\\medical_image_analysis\\cxr_model.h5', verbose=1, save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# es = keras.callbacks.EarlyStopping()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [keras.callbacks.TensorBoard(log_dir = 'mwglog/', histogram_freq=1),checkpointer]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(286, 128, 128, 3)\n",
      "(286, 128, 128, 1)\n"
     ]
    }
   ],
   "source": [
    "(list(train_dataset))[0]\n",
    "\n",
    "X_train = [i[0] for i in list(train_dataset)]\n",
    "X_train_arr = np.array(X_train)\n",
    "\n",
    "Y_train = [i[1] for i in list(train_dataset)]\n",
    "Y_train_arr = np.array(Y_train)\n",
    "\n",
    "print(X_train_arr.shape)\n",
    "print(Y_train_arr.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(22, 128, 128, 3)\n",
      "(22, 128, 128, 1)\n"
     ]
    }
   ],
   "source": [
    "(list(val_dataset))[0]\n",
    "\n",
    "X_test = [i[0] for i in list(val_dataset)]\n",
    "X_test_arr = np.array(X_test)\n",
    "\n",
    "Y_test = [i[1] for i in list(val_dataset)]\n",
    "Y_test_arr = np.array(Y_test)\n",
    "\n",
    "print(X_test_arr.shape)\n",
    "print(Y_test_arr.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/35\n",
      "9/9 [==============================] - ETA: 0s - loss: nan - accuracy: 0.7990\n",
      "Epoch 1: val_loss did not improve from inf\n",
      "9/9 [==============================] - 31s 3s/step - loss: nan - accuracy: 0.7990 - val_loss: nan - val_accuracy: 0.7924\n",
      "Epoch 2/35\n",
      "9/9 [==============================] - ETA: 0s - loss: nan - accuracy: 0.7990\n",
      "Epoch 2: val_loss did not improve from inf\n",
      "9/9 [==============================] - 27s 3s/step - loss: nan - accuracy: 0.7990 - val_loss: nan - val_accuracy: 0.7924\n",
      "Epoch 3/35\n",
      "9/9 [==============================] - ETA: 0s - loss: nan - accuracy: 0.7990\n",
      "Epoch 3: val_loss did not improve from inf\n",
      "9/9 [==============================] - 27s 3s/step - loss: nan - accuracy: 0.7990 - val_loss: nan - val_accuracy: 0.7924\n",
      "Epoch 4/35\n",
      "9/9 [==============================] - ETA: 0s - loss: nan - accuracy: 0.7990\n",
      "Epoch 4: val_loss did not improve from inf\n",
      "9/9 [==============================] - 26s 3s/step - loss: nan - accuracy: 0.7990 - val_loss: nan - val_accuracy: 0.7924\n",
      "Epoch 5/35\n",
      "9/9 [==============================] - ETA: 0s - loss: nan - accuracy: 0.7990\n",
      "Epoch 5: val_loss did not improve from inf\n",
      "9/9 [==============================] - 27s 3s/step - loss: nan - accuracy: 0.7990 - val_loss: nan - val_accuracy: 0.7924\n",
      "Epoch 6/35\n",
      "9/9 [==============================] - ETA: 0s - loss: nan - accuracy: 0.7990\n",
      "Epoch 6: val_loss did not improve from inf\n",
      "9/9 [==============================] - 41s 4s/step - loss: nan - accuracy: 0.7990 - val_loss: nan - val_accuracy: 0.7924\n",
      "Epoch 7/35\n",
      "9/9 [==============================] - ETA: 0s - loss: nan - accuracy: 0.7990\n",
      "Epoch 7: val_loss did not improve from inf\n",
      "9/9 [==============================] - 40s 4s/step - loss: nan - accuracy: 0.7990 - val_loss: nan - val_accuracy: 0.7924\n",
      "Epoch 8/35\n",
      "9/9 [==============================] - ETA: 0s - loss: nan - accuracy: 0.7990\n",
      "Epoch 8: val_loss did not improve from inf\n",
      "9/9 [==============================] - 37s 4s/step - loss: nan - accuracy: 0.7990 - val_loss: nan - val_accuracy: 0.7924\n",
      "Epoch 9/35\n",
      "9/9 [==============================] - ETA: 0s - loss: nan - accuracy: 0.7990\n",
      "Epoch 9: val_loss did not improve from inf\n",
      "9/9 [==============================] - 38s 4s/step - loss: nan - accuracy: 0.7990 - val_loss: nan - val_accuracy: 0.7924\n",
      "Epoch 10/35\n",
      "9/9 [==============================] - ETA: 0s - loss: nan - accuracy: 0.7990\n",
      "Epoch 10: val_loss did not improve from inf\n",
      "9/9 [==============================] - 38s 4s/step - loss: nan - accuracy: 0.7990 - val_loss: nan - val_accuracy: 0.7924\n",
      "Epoch 11/35\n",
      "9/9 [==============================] - ETA: 0s - loss: nan - accuracy: 0.7990\n",
      "Epoch 11: val_loss did not improve from inf\n",
      "9/9 [==============================] - 37s 4s/step - loss: nan - accuracy: 0.7990 - val_loss: nan - val_accuracy: 0.7924\n",
      "Epoch 12/35\n",
      "9/9 [==============================] - ETA: 0s - loss: nan - accuracy: 0.7990\n",
      "Epoch 12: val_loss did not improve from inf\n",
      "9/9 [==============================] - 49s 6s/step - loss: nan - accuracy: 0.7990 - val_loss: nan - val_accuracy: 0.7924\n",
      "Epoch 13/35\n",
      "9/9 [==============================] - ETA: 0s - loss: nan - accuracy: 0.7990\n",
      "Epoch 13: val_loss did not improve from inf\n",
      "9/9 [==============================] - 41s 5s/step - loss: nan - accuracy: 0.7990 - val_loss: nan - val_accuracy: 0.7924\n",
      "Epoch 14/35\n",
      "9/9 [==============================] - ETA: 0s - loss: nan - accuracy: 0.7990\n",
      "Epoch 14: val_loss did not improve from inf\n",
      "9/9 [==============================] - 37s 4s/step - loss: nan - accuracy: 0.7990 - val_loss: nan - val_accuracy: 0.7924\n",
      "Epoch 15/35\n",
      "9/9 [==============================] - ETA: 0s - loss: nan - accuracy: 0.7990\n",
      "Epoch 15: val_loss did not improve from inf\n",
      "9/9 [==============================] - 48s 5s/step - loss: nan - accuracy: 0.7990 - val_loss: nan - val_accuracy: 0.7924\n",
      "Epoch 16/35\n",
      "9/9 [==============================] - ETA: 0s - loss: nan - accuracy: 0.7990\n",
      "Epoch 16: val_loss did not improve from inf\n",
      "9/9 [==============================] - 39s 4s/step - loss: nan - accuracy: 0.7990 - val_loss: nan - val_accuracy: 0.7924\n",
      "Epoch 17/35\n",
      "9/9 [==============================] - ETA: 0s - loss: nan - accuracy: 0.7990\n",
      "Epoch 17: val_loss did not improve from inf\n",
      "9/9 [==============================] - 42s 5s/step - loss: nan - accuracy: 0.7990 - val_loss: nan - val_accuracy: 0.7924\n",
      "Epoch 18/35\n",
      "9/9 [==============================] - ETA: 0s - loss: nan - accuracy: 0.7990\n",
      "Epoch 18: val_loss did not improve from inf\n",
      "9/9 [==============================] - 47s 5s/step - loss: nan - accuracy: 0.7990 - val_loss: nan - val_accuracy: 0.7924\n",
      "Epoch 19/35\n",
      "9/9 [==============================] - ETA: 0s - loss: nan - accuracy: 0.7990\n",
      "Epoch 19: val_loss did not improve from inf\n",
      "9/9 [==============================] - 42s 5s/step - loss: nan - accuracy: 0.7990 - val_loss: nan - val_accuracy: 0.7924\n",
      "Epoch 20/35\n",
      "9/9 [==============================] - ETA: 0s - loss: nan - accuracy: 0.7990\n",
      "Epoch 20: val_loss did not improve from inf\n",
      "9/9 [==============================] - 43s 5s/step - loss: nan - accuracy: 0.7990 - val_loss: nan - val_accuracy: 0.7924\n",
      "Epoch 21/35\n",
      "9/9 [==============================] - ETA: 0s - loss: nan - accuracy: 0.7990\n",
      "Epoch 21: val_loss did not improve from inf\n",
      "9/9 [==============================] - 47s 5s/step - loss: nan - accuracy: 0.7990 - val_loss: nan - val_accuracy: 0.7924\n",
      "Epoch 22/35\n",
      "9/9 [==============================] - ETA: 0s - loss: nan - accuracy: 0.7990\n",
      "Epoch 22: val_loss did not improve from inf\n",
      "9/9 [==============================] - 36s 4s/step - loss: nan - accuracy: 0.7990 - val_loss: nan - val_accuracy: 0.7924\n",
      "Epoch 23/35\n",
      "9/9 [==============================] - ETA: 0s - loss: nan - accuracy: 0.7990\n",
      "Epoch 23: val_loss did not improve from inf\n",
      "9/9 [==============================] - 39s 4s/step - loss: nan - accuracy: 0.7990 - val_loss: nan - val_accuracy: 0.7924\n",
      "Epoch 24/35\n",
      "9/9 [==============================] - ETA: 0s - loss: nan - accuracy: 0.7990\n",
      "Epoch 24: val_loss did not improve from inf\n",
      "9/9 [==============================] - 30s 3s/step - loss: nan - accuracy: 0.7990 - val_loss: nan - val_accuracy: 0.7924\n",
      "Epoch 25/35\n",
      "9/9 [==============================] - ETA: 0s - loss: nan - accuracy: 0.7990\n",
      "Epoch 25: val_loss did not improve from inf\n",
      "9/9 [==============================] - 23s 3s/step - loss: nan - accuracy: 0.7990 - val_loss: nan - val_accuracy: 0.7924\n",
      "Epoch 26/35\n",
      "9/9 [==============================] - ETA: 0s - loss: nan - accuracy: 0.7990\n",
      "Epoch 26: val_loss did not improve from inf\n",
      "9/9 [==============================] - 24s 3s/step - loss: nan - accuracy: 0.7990 - val_loss: nan - val_accuracy: 0.7924\n",
      "Epoch 27/35\n",
      "9/9 [==============================] - ETA: 0s - loss: nan - accuracy: 0.7990\n",
      "Epoch 27: val_loss did not improve from inf\n",
      "9/9 [==============================] - 23s 3s/step - loss: nan - accuracy: 0.7990 - val_loss: nan - val_accuracy: 0.7924\n",
      "Epoch 28/35\n",
      "9/9 [==============================] - ETA: 0s - loss: nan - accuracy: 0.7990\n",
      "Epoch 28: val_loss did not improve from inf\n",
      "9/9 [==============================] - 23s 3s/step - loss: nan - accuracy: 0.7990 - val_loss: nan - val_accuracy: 0.7924\n",
      "Epoch 29/35\n",
      "9/9 [==============================] - ETA: 0s - loss: nan - accuracy: 0.7990\n",
      "Epoch 29: val_loss did not improve from inf\n",
      "9/9 [==============================] - 24s 3s/step - loss: nan - accuracy: 0.7990 - val_loss: nan - val_accuracy: 0.7924\n",
      "Epoch 30/35\n",
      "9/9 [==============================] - ETA: 0s - loss: nan - accuracy: 0.7990\n",
      "Epoch 30: val_loss did not improve from inf\n",
      "9/9 [==============================] - 23s 3s/step - loss: nan - accuracy: 0.7990 - val_loss: nan - val_accuracy: 0.7924\n",
      "Epoch 31/35\n",
      "9/9 [==============================] - ETA: 0s - loss: nan - accuracy: 0.7990\n",
      "Epoch 31: val_loss did not improve from inf\n",
      "9/9 [==============================] - 24s 3s/step - loss: nan - accuracy: 0.7990 - val_loss: nan - val_accuracy: 0.7924\n",
      "Epoch 32/35\n",
      "9/9 [==============================] - ETA: 0s - loss: nan - accuracy: 0.7990\n",
      "Epoch 32: val_loss did not improve from inf\n",
      "9/9 [==============================] - 24s 3s/step - loss: nan - accuracy: 0.7990 - val_loss: nan - val_accuracy: 0.7924\n",
      "Epoch 33/35\n",
      "9/9 [==============================] - ETA: 0s - loss: nan - accuracy: 0.7990\n",
      "Epoch 33: val_loss did not improve from inf\n",
      "9/9 [==============================] - 24s 3s/step - loss: nan - accuracy: 0.7990 - val_loss: nan - val_accuracy: 0.7924\n",
      "Epoch 34/35\n",
      "9/9 [==============================] - ETA: 0s - loss: nan - accuracy: 0.7990\n",
      "Epoch 34: val_loss did not improve from inf\n",
      "9/9 [==============================] - 31s 4s/step - loss: nan - accuracy: 0.7990 - val_loss: nan - val_accuracy: 0.7924\n",
      "Epoch 35/35\n",
      "9/9 [==============================] - ETA: 0s - loss: nan - accuracy: 0.7990\n",
      "Epoch 35: val_loss did not improve from inf\n",
      "9/9 [==============================] - 37s 4s/step - loss: nan - accuracy: 0.7990 - val_loss: nan - val_accuracy: 0.7924\n"
     ]
    }
   ],
   "source": [
    "results = model.fit(x=X_train_arr, y=Y_train_arr, validation_data = (X_test_arr,Y_test_arr), epochs=35, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
